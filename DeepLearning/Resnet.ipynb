{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from torchsummary import summary\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "from pathlib import Path\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义残差块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride=1, flag=False):\n",
    "        super().__init__()\n",
    "        if flag:\n",
    "            self.conv3 = nn.Conv2d(in_channel, out_channel, 1, stride=stride)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "            stride = 1\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, 3, padding=1, stride=stride)\n",
    "        self.norm1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, 3, padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.norm2(self.conv2(F.relu(self.norm1(self.conv1(x)))))\n",
    "        if self.conv3:\n",
    "            x = self.conv3(x)\n",
    "        return F.relu(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试残差块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 224, 224])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(16, 1, 224, 224)\n",
    "block = Residual(1, 1, flag=0, stride=2)\n",
    "block(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义复合残差块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resblock(num, channels):\n",
    "    layers = list()\n",
    "    for i in range(num):\n",
    "        flag = True if (i + 1) % 2 else False\n",
    "        stride = flag + 1\n",
    "        layers.append(Residual(channels[i], channels[i + 1], flag=flag, stride=stride))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义xavier初始化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(m):\n",
    "    if type(m) in [nn.Conv2d, nn.Linear]:\n",
    "        nn.init.xavier_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义残差网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU()\n",
       "   (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Residual(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (1): Residual(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Residual(\n",
       "   (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "   (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "   (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Residual(\n",
       "   (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Residual(\n",
       "   (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "   (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "   (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Residual(\n",
       "   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Residual(\n",
       "   (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "   (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "   (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Residual(\n",
       "   (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): AdaptiveAvgPool2d(output_size=1)\n",
       "   (1): Flatten(start_dim=1, end_dim=-1)\n",
       "   (2): Linear(in_features=512, out_features=10, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = (64, 128, 128, 256, 256, 512, 512)\n",
    "stage1 = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, 7, padding=3, stride=2),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3, stride=2, padding=1),\n",
    ")\n",
    "stage2 = nn.Sequential(Residual(64, 64), Residual(64, 64))\n",
    "stage3 = resblock(6, args)\n",
    "stage4 = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Flatten(), nn.Linear(512, 10))\n",
    "net = nn.Sequential(stage1, stage2, *stage3, stage4)\n",
    "list(net.children())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数量估计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [64, 64, 112, 112]           3,200\n",
      "       BatchNorm2d-2         [64, 64, 112, 112]             128\n",
      "              ReLU-3         [64, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [64, 64, 56, 56]               0\n",
      "            Conv2d-5           [64, 64, 56, 56]          36,928\n",
      "       BatchNorm2d-6           [64, 64, 56, 56]             128\n",
      "            Conv2d-7           [64, 64, 56, 56]          36,928\n",
      "       BatchNorm2d-8           [64, 64, 56, 56]             128\n",
      "          Residual-9           [64, 64, 56, 56]               0\n",
      "           Conv2d-10           [64, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-11           [64, 64, 56, 56]             128\n",
      "           Conv2d-12           [64, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-13           [64, 64, 56, 56]             128\n",
      "         Residual-14           [64, 64, 56, 56]               0\n",
      "           Conv2d-15          [64, 128, 28, 28]          73,856\n",
      "      BatchNorm2d-16          [64, 128, 28, 28]             256\n",
      "           Conv2d-17          [64, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-18          [64, 128, 28, 28]             256\n",
      "           Conv2d-19          [64, 128, 28, 28]           8,320\n",
      "         Residual-20          [64, 128, 28, 28]               0\n",
      "           Conv2d-21          [64, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-22          [64, 128, 28, 28]             256\n",
      "           Conv2d-23          [64, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-24          [64, 128, 28, 28]             256\n",
      "         Residual-25          [64, 128, 28, 28]               0\n",
      "           Conv2d-26          [64, 256, 14, 14]         295,168\n",
      "      BatchNorm2d-27          [64, 256, 14, 14]             512\n",
      "           Conv2d-28          [64, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-29          [64, 256, 14, 14]             512\n",
      "           Conv2d-30          [64, 256, 14, 14]          33,024\n",
      "         Residual-31          [64, 256, 14, 14]               0\n",
      "           Conv2d-32          [64, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-33          [64, 256, 14, 14]             512\n",
      "           Conv2d-34          [64, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-35          [64, 256, 14, 14]             512\n",
      "         Residual-36          [64, 256, 14, 14]               0\n",
      "           Conv2d-37            [64, 512, 7, 7]       1,180,160\n",
      "      BatchNorm2d-38            [64, 512, 7, 7]           1,024\n",
      "           Conv2d-39            [64, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-40            [64, 512, 7, 7]           1,024\n",
      "           Conv2d-41            [64, 512, 7, 7]         131,584\n",
      "         Residual-42            [64, 512, 7, 7]               0\n",
      "           Conv2d-43            [64, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-44            [64, 512, 7, 7]           1,024\n",
      "           Conv2d-45            [64, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-46            [64, 512, 7, 7]           1,024\n",
      "         Residual-47            [64, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-48            [64, 512, 1, 1]               0\n",
      "          Flatten-49                  [64, 512]               0\n",
      "           Linear-50                   [64, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,178,378\n",
      "Trainable params: 11,178,378\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 12.25\n",
      "Forward/backward pass size (MB): 3197.75\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 3252.65\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (1, 224, 224), batch_size=64, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor(),])\n",
    "mnist_train = datasets.FashionMNIST(\"./data\", train=True, transform=transform, download=True)\n",
    "mnist_test = datasets.FashionMNIST(\"./data\", train=False, transform=transform, download=True)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), 0.1)\n",
    "epochs = 10\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "data_train = data.DataLoader(mnist_train, batch_size=128, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指定设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Residual(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (2): Residual(\n",
       "    (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (3): Residual(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (4): Residual(\n",
       "    (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (5): Residual(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (6): Residual(\n",
       "    (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (7): Residual(\n",
       "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (8): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=1)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.apply(init_weight)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试输入输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential outsize torch.Size([16, 64, 56, 56])\n",
      "Sequential outsize torch.Size([16, 64, 56, 56])\n",
      "Residual outsize torch.Size([16, 128, 28, 28])\n",
      "Residual outsize torch.Size([16, 128, 28, 28])\n",
      "Residual outsize torch.Size([16, 256, 14, 14])\n",
      "Residual outsize torch.Size([16, 256, 14, 14])\n",
      "Residual outsize torch.Size([16, 512, 7, 7])\n",
      "Residual outsize torch.Size([16, 512, 7, 7])\n",
      "Sequential outsize torch.Size([16, 10])\n"
     ]
    }
   ],
   "source": [
    "x = x.cuda()\n",
    "for layer in net:\n",
    "    x = layer(x)\n",
    "    print(layer.__class__.__name__, \"outsize\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(net, data, loss, optimizer, epoch, device):\n",
    "    print(f\"第{epoch + 1}次迭代,网络训练中...\")\n",
    "    for x, y in data:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        l = loss(net(x), y)\n",
    "        l.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "泛化精度： tensor(0.9128, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def infer(data, net):\n",
    "    net.eval()\n",
    "    scores = list()\n",
    "    for feature, label in data:\n",
    "        feature = feature.cuda()\n",
    "        with torch.no_grad():\n",
    "            X = F.softmax(net(feature.view(-1, 1, 224, 224)), dim=1)\n",
    "        scores.append(X.argmax() == label)\n",
    "    accuracy = sum(scores) / len(scores)\n",
    "    return accuracy.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = list()\n",
    "for epoch in range(epochs):\n",
    "    trainer(net, data_train, optimizer, epoch, device)\n",
    "    acc.append(infer(mnist_test, net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.sans-serif\"] = \"SimHei\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.figure()\n",
    "plt.tight_layout()\n",
    "plt.plot(range(len(acc)), acc, ls=\"--\", label=\"泛化精度\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37b255bb5dc0d995b91bd1b934b878e610a26475f52eafaf29fdb395fb105534"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
