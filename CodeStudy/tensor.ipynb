{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.utils import data\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.32009542, -1.0410011 , -0.45408841,  1.15025677,  0.99723141],\n",
       "       [ 0.03599228,  1.0898217 , -1.17736566, -1.21532241, -1.63121653],\n",
       "       [-0.57987694,  2.34898176, -0.46289087,  1.14147415, -0.61507659]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(3, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.2       , 1.08368329, 0.20619628, 1.32309065, 0.99447048],\n",
       "        [1.2       , 1.18771134, 1.3861899 , 1.47700856, 2.66086736],\n",
       "        [1.2       , 5.5177153 , 0.21426796, 1.30296323, 0.37831921]]),\n",
       " array([[1.2       , 1.08368329, 0.20619628, 1.32309065, 0.99447048],\n",
       "        [1.2       , 1.18771134, 1.3861899 , 1.47700856, 2.66086736],\n",
       "        [1.2       , 5.5177153 , 0.21426796, 1.30296323, 0.37831921]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x\n",
    "x[:, 0] = 1.2\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60736245,  0.05312085,  1.88691183, -0.72999724, -0.99155226],\n",
       "       [ 0.20374399,  0.30048661, -0.41601636, -0.53726804,  0.43218936],\n",
       "       [ 0.45909998, -1.62834234, -0.55385048, -0.33428451,  0.74530595]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0].sort()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1c7b97f8a542fd9ca8103b5958cbf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.figure()\n",
    "plt.plot(range(3), x, label=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(10., requires_grad=True)\n",
    "b = torch.tensor(4.)\n",
    "c = torch.tensor(5., requires_grad=True)\n",
    "f = lambda x, y , c : x * y + c\n",
    "for i in range(4):\n",
    "    l = f(a, b, c)\n",
    "    l.backward()\n",
    "    # with torch.no_grad():\n",
    "    #     a += a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5399, 0.1556, 1.6685, 2.0749],\n",
       "         [0.2134, 1.5019, 0.7016, 1.1997],\n",
       "         [0.7786, 1.5289, 0.6386, 1.3042],\n",
       "         [3.7195, 3.2603, 0.5434, 1.1997]],\n",
       "\n",
       "        [[0.8360, 0.2738, 1.1483, 0.4526],\n",
       "         [1.8703, 2.1785, 3.0973, 0.2953],\n",
       "         [2.0495, 0.2592, 0.9236, 1.2743],\n",
       "         [0.9476, 2.0289, 1.9265, 0.5526]],\n",
       "\n",
       "        [[0.0885, 0.5400, 1.7490, 1.0004],\n",
       "         [1.2619, 0.5605, 0.9871, 0.5597],\n",
       "         [1.8031, 1.3143, 1.7468, 2.7397],\n",
       "         [0.9348, 1.8272, 0.2260, 0.5582]],\n",
       "\n",
       "        [[0.7739, 1.5960, 2.1234, 1.3273],\n",
       "         [0.7942, 0.9123, 1.9258, 2.7585],\n",
       "         [2.5981, 2.7038, 0.3616, 0.2986],\n",
       "         [1.0910, 2.3436, 0.7527, 1.1329]],\n",
       "\n",
       "        [[0.2778, 1.2651, 1.4387, 2.8061],\n",
       "         [1.2079, 1.2134, 3.3150, 1.2151],\n",
       "         [0.7080, 2.4715, 0.4660, 1.5311],\n",
       "         [0.2506, 1.4355, 1.0796, 0.7543]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(5, 3, 4, 4)\n",
    "target = torch.randint(3, (5, 4, 4))\n",
    "F.cross_entropy(input, target, reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 bilinear kernel\n",
    "def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
    "    \"\"\"\n",
    "    return a bilinear filter tensor\n",
    "    \"\"\"\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros(\n",
    "        (in_channels, out_channels, kernel_size, kernel_size), dtype=\"float32\"\n",
    "    )\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return torch.from_numpy(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0625, 0.1875, 0.1875, 0.0625],\n",
       "          [0.1875, 0.5625, 0.5625, 0.1875],\n",
       "          [0.1875, 0.5625, 0.5625, 0.1875],\n",
       "          [0.0625, 0.1875, 0.1875, 0.0625]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilinear_kernel(1, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "x, x[:, :2], x[:, None, :2], torch.max(x[:, None, :2], x[:, :2])\n",
    "torch.argmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(20).reshape(2, 5, 2)\n",
    "x.sum(dim=2)\n",
    "torch.zeros(20, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_trans(input, kernel):\n",
    "    h, w = kernel.shape\n",
    "    Y = torch.zeros(input.shape[0] + h - 1, input.shape[1] + w - 1)\n",
    "    for i in range(input.shape[0]):\n",
    "        for j in range(input.shape[1]):\n",
    "            Y[i : i + h, j : j + w] += kernel * input[i, j]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,  -0.7475,  -1.5456,  -2.4634,  -0.3913,  -0.3590],\n",
       "        [ -2.9900,  -5.7411,  -9.9993, -15.6584,  -8.1336,  -6.1172],\n",
       "        [-13.1840, -22.9570, -36.6328, -45.3979, -22.3950, -17.2545],\n",
       "        [-31.7679, -45.6735, -71.6931, -80.4582, -38.8714, -29.5984],\n",
       "        [-38.3919, -54.8722, -90.5229, -98.3702, -52.2316, -39.6686],\n",
       "        [-25.1699, -24.8917, -41.2687, -44.3746, -13.9208, -18.0968]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.arange(16).reshape(4, 4)\n",
    "kernel = torch.randn(3, 3)\n",
    "conv_trans(input, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sythentic_data(w, b, num):\n",
    "    x = torch.normal(0, 2, size=(num, len(w)))\n",
    "    y = x @ w + b + torch.randn(num)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(x, y, batch_size):\n",
    "    n = len(x)\n",
    "    indices = list(range(n))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, n, batch_size):\n",
    "        id = indices[i:min(i + batch_size, n)]\n",
    "        yield x[id], y[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mseloss(x, y, w, b):\n",
    "    h = x @ w + b\n",
    "    return torch.sum(torch.pow(h - y, 2)) / (2 * len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(*params, lr):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(41.4106, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_w = torch.tensor([2, 1.5])\n",
    "true_b = torch.tensor(3)\n",
    "num = 256\n",
    "batch_size =20\n",
    "X, Y = sythentic_data(true_w, true_b, num)\n",
    "w = torch.randn(2, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True, dtype=torch.float)\n",
    "epoch = 40\n",
    "lr = 0.01\n",
    "feature, label = next(load_data(X, Y, batch_size))\n",
    "mseloss(feature, label, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(epoch):\n",
    "    for f, l in load_data(X, Y, batch_size):\n",
    "        mseloss(f, l, w, b).backward()\n",
    "        gradientDescent(w, b, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'Tensor' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2156/3071993004.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'Tensor' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "w = w - w.grad\n",
    "id(w), id(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4668/3416299961.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;31m# 涉及梯度运算，会导致运算后参数变为其他类型，从而无法更新\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# w.grad.zero_()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "w -= w.grad # requires_grad=True不能执行替换操作，因为张量保存的梯度与张量值有关，所以pytorch会报错\n",
    "# w.grad.zero_()\n",
    "type(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.arange(6.).reshape(2, 3)\n",
    "x2 = torch.arange(6., 12., requires_grad=True).reshape(2, 3)\n",
    "y = x1 * x2\n",
    "y.backward(gradient=torch.ones(y.shape))\n",
    "x1, x2, torch.stack([x1, x2], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Conv2d(6, 16, 5, 5), nn.Linear(16 * 5 * 5, 20)) # 矩阵形状为16*6*5*5\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(1, 4, (2, 3, 2, 2))                                                                                                                \n",
    "X, X.mean(axis=(0, 2, 3), keepdims=True), X.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(x, gamma, beta, e):\n",
    "    var = x.var(dim=(0, 2, 3), keepdim=True)\n",
    "    x_hat = (x - x.mean(dim=(0, 2, 3), keepdim=True)) / (var + e)\n",
    "    y = gamma * x_hat + beta\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(4, 2, 3, 2)\n",
    "gamma = torch.ones(a.shape)\n",
    "beta = torch.zeros(a.shape)\n",
    "e = 0.001\n",
    "batch_norm(a, gamma, beta, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(15).reshape(5, 3)\n",
    "b = torch.arange(3).reshape(1, 3)\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prenet = models.vgg19()\n",
    "prenet.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(1, 4, (2, 3, 2, 2))\n",
    "b = torch.randint(5, 8, (2, 3, 2, 2))\n",
    "torch.cat([a, b], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.rand(3, 3) \n",
    "d = torch.rand(3, 3)\n",
    "c[:, 0], torch.stack((c[:, 0], c[:, 1], d[:, 0], d[:, 1]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.arange(4).reshape(2, 2)\n",
    "torch.repeat_interleave(b, 2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# @save\n",
    "def multibox_prior(data, sizes, ratios):\n",
    "    \"\"\"生成以每个像素为中心具有不同形状的锚框。\"\"\"\n",
    "    in_height, in_width = data.shape[-2:]\n",
    "    device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)\n",
    "    boxes_per_pixel = num_sizes + num_ratios - 1\n",
    "    size_tensor = torch.tensor(sizes, device=device)\n",
    "    ratio_tensor = torch.tensor(ratios, device=device)\n",
    "\n",
    "    # 为了将锚点移动到像素的中心，需要设置偏移量。\n",
    "    # 因为一个像素的的高为1且宽为1，我们选择偏移我们的中心0.5\n",
    "    offset_h, offset_w = 0.5, 0.5\n",
    "    steps_h = 1.0 / in_height  # Scaled steps in y axis\n",
    "    steps_w = 1.0 / in_width  # Scaled steps in x axis\n",
    "\n",
    "    # 生成锚框的所有中心点\n",
    "    center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h\n",
    "    center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w\n",
    "    shift_y, shift_x = torch.meshgrid(center_h, center_w)\n",
    "    shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)\n",
    "\n",
    "    # 生成“boxes_per_pixel”个高和宽，\n",
    "    # 之后用于创建锚框的四角坐标 (xmin, xmax, ymin, ymax)\n",
    "    w = (\n",
    "        torch.cat(\n",
    "            (\n",
    "                size_tensor * torch.sqrt(ratio_tensor[0]),\n",
    "                sizes[0] * torch.sqrt(ratio_tensor[1:]),\n",
    "            )\n",
    "        )\n",
    "        * in_height\n",
    "        / in_width\n",
    "    )  # Handle rectangular inputs\n",
    "    h = torch.cat(\n",
    "        (\n",
    "            size_tensor / torch.sqrt(ratio_tensor[0]),\n",
    "            sizes[0] / torch.sqrt(ratio_tensor[1:]),\n",
    "        )\n",
    "    )\n",
    "    # 除以2来获得半高和半宽\n",
    "    anchor_manipulations = (\n",
    "        torch.stack((-w, -h, w, h)).T.repeat(in_height * in_width, 1) / 2\n",
    "    )\n",
    "\n",
    "    # 每个中心点都将有“boxes_per_pixel”个锚框，\n",
    "    # 所以生成含所有锚框中心的网格，重复了“boxes_per_pixel”次\n",
    "    out_grid = torch.stack(\n",
    "        [shift_x, shift_y, shift_x, shift_y], dim=1\n",
    "    ).repeat_interleave(boxes_per_pixel, dim=0)\n",
    "    output = out_grid + anchor_manipulations\n",
    "    return output.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "img = plt.imread(r'D:\\WorkSpace\\PythonProject\\pytorch\\img\\catdog.jpg')\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "print(h, w)\n",
    "X = torch.rand(size=(2, 3, h, w))\n",
    "Y = multibox_prior(X, sizes=[0.75, 0.5, 0.25], ratios=[1, 2, 0.5])\n",
    "Y.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37b255bb5dc0d995b91bd1b934b878e610a26475f52eafaf29fdb395fb105534"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
